{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 텐서플로우를 구성하는 가장 기초적인 데이터 단위\n",
    " - n 차원 배열의 집합 또는 n 차원 배열을 의미\n",
    " - rank: 텐서의 차원\n",
    " - 텐서의 표현은 `numpy` 배열을 사용\n",
    " \n",
    " #컴파일형 언어 정의 먼저 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. # a rank 0 tensor; a scalar with shape []\n",
    "[1., 2., 3.] # a rank 1 tensor; a vector with shape [3],\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3],\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 1) 연산 그래프(computational graph) 정의 \n",
    "  - 연산그래프는 텐서플로우 작업을 순차적으로 정의(표현)한 것으로 노드와 에지를 갖는 그래프 형태를 갖음 \n",
    "  - 연산그래프의 노드에는 텐서를 입력값으로 받아 연산하는 작업들이 위치 : `tf.Operation`\n",
    "  - 연산그래프의 에지에는 노드에 정의된 연산간에 주고 받는 데이터 들을 표현(텐서들이 그래프 상에서 흐름.) `tf.Tensor`\n",
    "  \n",
    "  텐서를 그래프로 흘려보낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 2) 연산 그래프를 실행\n",
    "  - 연산그래프의 실행은 `tf.Session` 객체,텐서플로우가 실행되는 환경을 만들어서 진행됨\n",
    "  - 연산그래프의 작업을 CPU, GPU에 배정하고 실행을 위한 메서드를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [default 그래프에 정의하기]\n",
    " - 3개의 노드(2개: constant op, 1개 matmul op)\n",
    " - 특정 그래프 객체에 명시적으로 연산을 정의하지 않는한 모든 연산은 전역 default 그래프에 정의됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # 연산 정의, 그래프 정의하지 않으면 default 그래프 사용\n",
    "mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32) # constant 텐서 생성하라 타입은 플로트32, 정의하면 그래프 노드상에 올라감\n",
    "mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "product = tf.matmul(mat_a, mat_b) # 매트릭스 연산하라\n",
    "\n",
    "print(tf.get_default_graph() is product.graph) # 어디에 올라가 있는지 확인, 디폴트 그래프에 올라가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [특정 그래프에 연산 정의하기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g_1 = tf.Graph() # 연결되지 않은 별도 그래프에 연산올리고 싶으면 g_1 그래프 선언하고 선언된 g_1을 디폴트 그래프로 만듬\n",
    "with g_1.as_default():\n",
    "    mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "    mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "    product = tf.matmul(mat_a, mat_b)\n",
    "    print(product.graph is g_1)\n",
    "\n",
    "g_2 = tf.Graph() # g_1과 별개 그래프에 올라감\n",
    "with g_2.as_default():\n",
    "    mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "    mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "    product = tf.matmul(mat_a, mat_b)\n",
    "    print(product.graph is g_2)\n",
    "# with tf.Graph().as_default() as g_2:\n",
    "#     mat_a = tf.constant([[3.0, 3.0]], dtype=tf.float32)\n",
    "#     mat_b = tf.constant([[2.0],[2.0]], dtype=tf.float32)\n",
    "#     product = tf.matmul(mat_a, mat_b)\n",
    "#     print(product.graph is g_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [그래프 실행하기]\n",
    " - session 객체의 run 매서드 호출\n",
    " - default 그래프에 정의한 3개의 작업이 실행 (graph=None)\n",
    " - 사용한 session 반환\n",
    "\n",
    "텐서플로우 실행 환경 불러와야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(graph=g_2) # g_2 그래프 상에서 실행할거다\n",
    "print(sess.run(product)) # product 하나만 호출해도 다 연결되어 있어서 실행됨\n",
    "sess.close() # 세션 쓰고 클로즈해야함 or with 컨텍스트 구문 쓰기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - session 컨텍스트 매니저 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g_2) as sess:\n",
    "    print(sess.run(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 연산 자원 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g_2) as sess:\n",
    "    with tf.device('/gpu:0'):\n",
    "        print(sess.run(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [인터렉티브한 이용]\n",
    "  - Tensor.eval(), Operation.run() 메서드 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2. -1.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession() # 이거 먼저 불러야함\n",
    "x = tf.Variable([1.0,2.0])\n",
    "a = tf.constant([3.0,3.0])\n",
    "x.initializer.run() # 무조건 실행되어야 함\n",
    "sub = tf.subtract(x,a)\n",
    "print(sub.eval()) # 세션에 안 넣어도 결과 볼 수 있음\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow tf.constant, tf.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 연산 그래프에 정의된 연산을 수행하기 위해 필요한 데이터 값을 입력 위한 수단 \n",
    " \n",
    "그래프 상에서 데이터 만들어서 흘려보냄\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3-1. tf.constant\n",
    " - 상수 텐서를 생성하는 작업으로, `tf.constant` 연산 정의시 제공한 초기값을 갖는 텐서를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3-2. tf.Variable\n",
    " - 텐서플로우 프로그램에서 연산의 결과가 공유되고, 상태를 유지해야하는 경우 사용 \n",
    "   - ex) 학습을 진행하면서 모델의 파라미터가 업데이트 되야하므로 모델의 파라미터를 변수로 표현\n",
    " - 변수 연산을 정의하기 위해 텐서를 초기값으로 부여, 초기값으로 제공한 텐서로 변수 type과 shape이 결정됨\n",
    " - 변수 연산이 정의되면 타입과 변수 type과 shape은 고정됨, 변수 값인 텐서를 assign 메서드로 변경\n",
    " - 연산을 실행하기 전, 그래프 상에 정의된 변수를 명시적으로 초기화하는 작업 필요\n",
    "   - 초기화 연산을 실행(`tf.global_variable_initializer()`), 변수 값이 저장된 파일에서 복구, `assign` 메서드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name=\"counter\") # 초기값 주고 Variable 이름 줌 Variable 연산 정의\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "init_op = tf.global_variables_initializer() #Variable 선언시 Variable에 대한 초기화 작업 필요, 세션 run 전에...\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### [변수의 저장과 복구]\n",
    "  - 변수를 이름과 텐서 값을 매핑해놓은 바이너리 파일(`.ckpt`)에 저장 가능\n",
    "  - `tf.train.Saver()` 객체를 이용하여 그래프 전체 변수와 지정된 리스트 변수를 저장하고 복구\n",
    "  - 저장될 때 사용되는 변수 명은 `Variable.name`이 기본 값\n",
    "  - `tf.train.Saver()` 객체에 딕셔너리를 저장할 이름(key), 저장할 값(value)로 전달하여 저장시 사용할 이름을 변경하거나 변수를 선택적으로 저장 가능\n",
    "    - ex) `tf.train.Saver({\"saved_v\":v})`\n",
    "  - 전체 변수를 파일에서 복구 시 변수 초기화가 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./tmp/ckpt/model.ckpt\n",
      "tensor_name:  Variable\n",
      "[1. 2.]\n",
      "tensor_name:  counter\n",
      "0\n",
      "tensor_name:  v1\n",
      "[1. 1. 1.]\n",
      "tensor_name:  v2\n",
      "[-1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Create some variables.\n",
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "\n",
    "v1 = tf.Variable(tf.zeros([3]), name=\"v1\")\n",
    "v2 = tf.Variable(tf.zeros([3]), name=\"v2\")\n",
    "    \n",
    "inc_v1 = v1.assign(v1+1) # Variable 업데이트\n",
    "dec_v2 = v2.assign(v2-1)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver() # 세션 run 할 때 넣어줌\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, and save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "  # Do some work with the model.\n",
    "  inc_v1.op.run() # sess.run(inc_v1)과 같음\n",
    "  dec_v2.op.run()\n",
    "  # Save the variables to disk.\n",
    "  shutil.rmtree(\"./tmp/ckpt\")\n",
    "  os.mkdir(\"./tmp/ckpt\")\n",
    "  save_path = saver.save(sess, \"./tmp/ckpt/model.ckpt\")\n",
    "  print(\"Model saved in path: %s\" % save_path)\n",
    "    \n",
    "    \n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "chkp.print_tensors_in_checkpoint_file(save_path, tensor_name='',  all_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt/model.ckpt\n",
      "Model restored.\n",
      "v1 : [1. 1. 1.]\n",
      "v2 : [-1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.Variable(tf.zeros([3]), name=\"v1\")\n",
    "v2 = tf.Variable(tf.zeros([3]), name=\"v2\")\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:  \n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"./tmp/ckpt/model.ckpt\") # 저장된 변수 불러옴\n",
    "  print(\"Model restored.\")\n",
    "  # Check the values of the variables\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### - tf.get_variable()\n",
    "  - `tf.Variable`과 같이 변수 정의하는 다른 방법으로 생성된 변수를 가져오거나 존재하지 않을 시 새롭게 생성\n",
    "  - `tf.variable_scope`가 `tf.get_variable`로 정의된 변수의 네임스페이스를 관리\n",
    "     - ex) 매우 깊은 층을 갖는 심층심경망 네트워크 구현시 각 층마다 변수를 정의하는 데 따른 불편함을 해결 \n",
    "     - 코드 모듈화를 더 쉽게할 수 있다는 이점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "weight1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "bias1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "weight2 = tf.Variable(tf.random_normal([2, 2]), name='weight2')\n",
    "bias2 = tf.Variable(tf.random_normal([2]), name='bias2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.variable_scope(\"layer1\", reuse=tf.AUTO_REUSE):\n",
    "    weight = tf.get_variable(\"weight\", shape=[2,2], initializer = tf.random_normal_initializer) # variable scope에서 weight 있으면 생성하지 말고 가져와라\n",
    "    bias = tf.get_variable(\"bias\", shape=[2], initializer = tf.random_normal_initializer) # 변수명, shape, initializer 3가지 꼭 정의 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fetches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 그래프 상에 정의된 작업 하나 이상의 작업 실행 결과 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([21.], dtype=float32), array([7.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "input1 = tf.constant([3.0])\n",
    "input2 = tf.constant([2.0])\n",
    "input3 = tf.constant([5.0])\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  result = sess.run([mul, intermed]) # result1, result2 = sess.run([mul, intermed]) 각각 받을 수 있음\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 실행 시점에 정의된 연산 그래프 상으로 텐서 값을 제공하는 매커니즘\n",
    " - tf.placeholder를 이용 텐서(데이터)가 연산 그래프에 입력될 입력 공간을 확보\n",
    " \n",
    " 외부 데이터 가져와서 정의한 그래프에 입력해서 연산 결과 받아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.312341   1.3715625  1.0564284  0.8542057 ]\n",
      " [0.6672931  0.9368535  0.673175   0.6187724 ]\n",
      " [0.9685603  1.0968544  0.87165964 0.69370997]\n",
      " [0.45783332 0.6832585  0.50909007 0.5343857 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x1 = tf.placeholder(tf.float32, shape=(4, 4), name='input1') # placeholder 입력 공간 만들기\n",
    "x2 = tf.placeholder(tf.float32, shape=(4, 4), name='input2')\n",
    "y = tf.matmul(x1, x2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#   print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
    "  arr = np.random.rand(4, 4)\n",
    "  print(sess.run(y, feed_dict={x1: arr, x2:arr})) # 딕셔너리로 줌, 타입과 shape 맞춰서 줘야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization : Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 텐서플로우가 제공하는 텐서보드를 활용하여 연산 그래프를 시각화\n",
    " - 그래프 실행 후 연산 결과 시각화\n",
    " - `tf.summary.FileWriter()` 객체에 연산 그래프와 연산 결과 값을 저장 후 텐서보드로 시각화   \n",
    " - 벡터: `tf.summary.histogram()`, 스칼라: `tf.summary.scalar()`로 시각화할 연산 값 설정\n",
    " - 텐서보드 실행 => 터미널에서 `tensorboard --logdir=\"./logs/xor_log\"` 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7368835 [array([[-1.5929914 ,  1.0429456 ],\n",
      "       [-0.980696  , -0.16480164]], dtype=float32), array([[ 1.0005004 ],\n",
      "       [-0.29604137]], dtype=float32)]\n",
      "100 0.6830594 [array([[-1.1259056,  1.3097087],\n",
      "       [-0.9362842, -0.846473 ]], dtype=float32), array([[ 1.1672261 ],\n",
      "       [-0.19308008]], dtype=float32)]\n",
      "200 0.6282494 [array([[-1.2401738,  3.1884916],\n",
      "       [-1.5244046, -2.54507  ]], dtype=float32), array([[ 1.6387883 ],\n",
      "       [-0.88963354]], dtype=float32)]\n",
      "300 0.5147696 [array([[-1.4998668,  4.7438984],\n",
      "       [-2.504844 , -4.267776 ]], dtype=float32), array([[ 2.5047252],\n",
      "       [-2.0730727]], dtype=float32)]\n",
      "400 0.44439247 [array([[-1.7855045,  5.605183 ],\n",
      "       [-3.412241 , -5.412506 ]], dtype=float32), array([[ 3.254652 ],\n",
      "       [-2.9803445]], dtype=float32)]\n",
      "500 0.40874672 [array([[-2.0189302,  6.1049285],\n",
      "       [-4.109908 , -6.194042 ]], dtype=float32), array([[ 3.833376 ],\n",
      "       [-3.6242013]], dtype=float32)]\n",
      "600 0.38940126 [array([[-2.201203 ,  6.431354 ],\n",
      "       [-4.6572356, -6.773777 ]], dtype=float32), array([[ 4.290191 ],\n",
      "       [-4.1067686]], dtype=float32)]\n",
      "700 0.3778948 [array([[-2.3468473,  6.6650224],\n",
      "       [-5.103515 , -7.232069 ]], dtype=float32), array([[ 4.664207],\n",
      "       [-4.488795]], dtype=float32)]\n",
      "800 0.37051156 [array([[-2.4667945,  6.8434186],\n",
      "       [-5.479438 , -7.6108847]], dtype=float32), array([[ 4.9801507],\n",
      "       [-4.8040743]], dtype=float32)]\n",
      "900 0.36548564 [array([[-2.5682135,  6.9860334],\n",
      "       [-5.8042083, -7.934162 ]], dtype=float32), array([[ 5.2536945],\n",
      "       [-5.072441 ]], dtype=float32)]\n",
      "1000 0.36190298 [array([[-2.655825 ,  7.1039886],\n",
      "       [-6.0903687, -8.216639 ]], dtype=float32), array([[ 5.495146],\n",
      "       [-5.306283]], dtype=float32)]\n",
      "1100 0.35925418 [array([[-2.7328305,  7.2041116],\n",
      "       [-6.3464737, -8.467981 ]], dtype=float32), array([[ 5.711575],\n",
      "       [-5.51378 ]], dtype=float32)]\n",
      "1200 0.35723662 [array([[-2.8014762,  7.290845 ],\n",
      "       [-6.5785856, -8.69483  ]], dtype=float32), array([[ 5.9080095],\n",
      "       [-5.700581 ]], dtype=float32)]\n",
      "1300 0.35566235 [array([[-2.8633888,  7.3672137],\n",
      "       [-6.791142 , -8.90195  ]], dtype=float32), array([[ 6.0881324],\n",
      "       [-5.8707333]], dtype=float32)]\n",
      "1400 0.3544087 [array([[-2.9197848,  7.435369 ],\n",
      "       [-6.987488 , -9.092862 ]], dtype=float32), array([[ 6.2547193],\n",
      "       [-6.0272284]], dtype=float32)]\n",
      "1500 0.35339314 [array([[-2.9715736,  7.4968653],\n",
      "       [-7.1701827, -9.270226 ]], dtype=float32), array([[ 6.409915],\n",
      "       [-6.172341]], dtype=float32)]\n",
      "1600 0.3525583 [array([[-3.019475 ,  7.552882 ],\n",
      "       [-7.3412547, -9.436124 ]], dtype=float32), array([[ 6.5554056],\n",
      "       [-6.3078356]], dtype=float32)]\n",
      "1700 0.35186297 [array([[-3.0640595,  7.6043215],\n",
      "       [-7.502316 , -9.592205 ]], dtype=float32), array([[ 6.692535 ],\n",
      "       [-6.4351053]], dtype=float32)]\n",
      "1800 0.35127765 [array([[-3.105783 ,  7.6518936],\n",
      "       [-7.654685 , -9.739782 ]], dtype=float32), array([[ 6.822398 ],\n",
      "       [-6.5552697]], dtype=float32)]\n",
      "1900 0.35078007 [array([[-3.1450074,  7.696122 ],\n",
      "       [-7.7994347, -9.87994  ]], dtype=float32), array([[ 6.9458957],\n",
      "       [-6.669246 ]], dtype=float32)]\n",
      "2000 0.3503533 [array([[ -3.1820436,   7.737522 ],\n",
      "       [ -7.9374557, -10.013576 ]], dtype=float32), array([[ 7.063775],\n",
      "       [-6.777787]], dtype=float32)]\n",
      "2100 0.34998465 [array([[ -3.2171457,   7.7764134],\n",
      "       [ -8.0695095, -10.141434 ]], dtype=float32), array([[ 7.176671 ],\n",
      "       [-6.8815255]], dtype=float32)]\n",
      "2200 0.3496638 [array([[ -3.2505267,   7.8130803],\n",
      "       [ -8.196236 , -10.264143 ]], dtype=float32), array([[ 7.285111 ],\n",
      "       [-6.9809904]], dtype=float32)]\n",
      "2300 0.34938267 [array([[ -3.282367 ,   7.8478312],\n",
      "       [ -8.318174 , -10.382236 ]], dtype=float32), array([[ 7.389554 ],\n",
      "       [-7.0766344]], dtype=float32)]\n",
      "2400 0.34913525 [array([[ -3.3128285,   7.8809114],\n",
      "       [ -8.435789 , -10.496194 ]], dtype=float32), array([[ 7.4903946],\n",
      "       [-7.1688466]], dtype=float32)]\n",
      "2500 0.34891632 [array([[ -3.3420415,   7.912429 ],\n",
      "       [ -8.549506 , -10.6064005]], dtype=float32), array([[ 7.5879755],\n",
      "       [-7.2579613]], dtype=float32)]\n",
      "2600 0.3487215 [array([[ -3.3701208,   7.9425445],\n",
      "       [ -8.659676 , -10.713208 ]], dtype=float32), array([[ 7.6825933],\n",
      "       [-7.344269 ]], dtype=float32)]\n",
      "2700 0.34854767 [array([[ -3.3971636,   7.971395 ],\n",
      "       [ -8.766613 , -10.816908 ]], dtype=float32), array([[ 7.774507],\n",
      "       [-7.428021]], dtype=float32)]\n",
      "2800 0.3483919 [array([[ -3.4232748,   7.9990935],\n",
      "       [ -8.870584 , -10.917786 ]], dtype=float32), array([[ 7.863954 ],\n",
      "       [-7.5094495]], dtype=float32)]\n",
      "2900 0.34825152 [array([[ -3.4485178,   8.025744 ],\n",
      "       [ -8.971842 , -11.0160675]], dtype=float32), array([[ 7.9511366],\n",
      "       [-7.5887475]], dtype=float32)]\n",
      "3000 0.34812486 [array([[ -3.4729548,   8.05144  ],\n",
      "       [ -9.070601 , -11.111963 ]], dtype=float32), array([[ 8.03624  ],\n",
      "       [-7.6660924]], dtype=float32)]\n",
      "3100 0.34801012 [array([[ -3.4966624,   8.076258 ],\n",
      "       [ -9.167056 , -11.205664 ]], dtype=float32), array([[ 8.119423],\n",
      "       [-7.741639]], dtype=float32)]\n",
      "3200 0.3479061 [array([[ -3.5197005,   8.100341 ],\n",
      "       [ -9.261386 , -11.29734  ]], dtype=float32), array([[ 8.200834 ],\n",
      "       [-7.8155303]], dtype=float32)]\n",
      "3300 0.34781152 [array([[ -3.5421083,   8.123833 ],\n",
      "       [ -9.35372  , -11.387172 ]], dtype=float32), array([[ 8.28061  ],\n",
      "       [-7.8878956]], dtype=float32)]\n",
      "3400 0.34772506 [array([[ -3.5639331,   8.146642 ],\n",
      "       [ -9.444236 , -11.475277 ]], dtype=float32), array([[ 8.358865 ],\n",
      "       [-7.9588437]], dtype=float32)]\n",
      "3500 0.34764567 [array([[ -3.5852344,   8.168819 ],\n",
      "       [ -9.533051 , -11.561779 ]], dtype=float32), array([[ 8.435704],\n",
      "       [-8.02848 ]], dtype=float32)]\n",
      "3600 0.34757343 [array([[ -3.606015,   8.190412],\n",
      "       [ -9.620277, -11.646779]], dtype=float32), array([[ 8.511231],\n",
      "       [-8.096894]], dtype=float32)]\n",
      "3700 0.34750694 [array([[ -3.6262832,   8.21146  ],\n",
      "       [ -9.706051 , -11.730385 ]], dtype=float32), array([[ 8.585534],\n",
      "       [-8.164176]], dtype=float32)]\n",
      "3800 0.34744555 [array([[ -3.6461327,   8.232001 ],\n",
      "       [ -9.790446 , -11.81269  ]], dtype=float32), array([[ 8.658693],\n",
      "       [-8.230399]], dtype=float32)]\n",
      "3900 0.34738886 [array([[ -3.6655762,   8.2520685],\n",
      "       [ -9.873542 , -11.893777 ]], dtype=float32), array([[ 8.730783],\n",
      "       [-8.295636]], dtype=float32)]\n",
      "4000 0.34733665 [array([[ -3.6846244,   8.271695 ],\n",
      "       [ -9.955424 , -11.973724 ]], dtype=float32), array([[ 8.801879],\n",
      "       [-8.359951]], dtype=float32)]\n",
      "4100 0.34728834 [array([[ -3.7033014,   8.290903 ],\n",
      "       [-10.036168 , -12.052605 ]], dtype=float32), array([[ 8.872042],\n",
      "       [-8.423405]], dtype=float32)]\n",
      "4200 0.34724385 [array([[ -3.7216318,   8.309721 ],\n",
      "       [-10.115846 , -12.130486 ]], dtype=float32), array([[ 8.941321],\n",
      "       [-8.48605 ]], dtype=float32)]\n",
      "4300 0.34720248 [array([[ -3.739627,   8.328172],\n",
      "       [-10.194517, -12.207429]], dtype=float32), array([[ 9.009781],\n",
      "       [-8.547936]], dtype=float32)]\n",
      "4400 0.34716377 [array([[ -3.7572482,   8.346275 ],\n",
      "       [-10.272267 , -12.283489 ]], dtype=float32), array([[ 9.077464 ],\n",
      "       [-8.6091175]], dtype=float32)]\n",
      "4500 0.3471282 [array([[ -3.7745912,   8.364056 ],\n",
      "       [-10.349157 , -12.35872  ]], dtype=float32), array([[ 9.144426],\n",
      "       [-8.669634]], dtype=float32)]\n",
      "4600 0.34709474 [array([[ -3.7916677,   8.381528 ],\n",
      "       [-10.425205 , -12.433167 ]], dtype=float32), array([[ 9.210705],\n",
      "       [-8.729527]], dtype=float32)]\n",
      "4700 0.34706384 [array([[ -3.808488,   8.398707],\n",
      "       [-10.500455, -12.506881]], dtype=float32), array([[ 9.276337],\n",
      "       [-8.788832]], dtype=float32)]\n",
      "4800 0.34703496 [array([[ -3.8250608,   8.415609 ],\n",
      "       [-10.574958 , -12.579899 ]], dtype=float32), array([[ 9.341362],\n",
      "       [-8.847582]], dtype=float32)]\n",
      "4900 0.34700778 [array([[ -3.8413951,   8.432251 ],\n",
      "       [-10.648743 , -12.652263 ]], dtype=float32), array([[ 9.405809],\n",
      "       [-8.90581 ]], dtype=float32)]\n",
      "5000 0.34698272 [array([[ -3.8574915,   8.448646 ],\n",
      "       [-10.721859 , -12.724007 ]], dtype=float32), array([[ 9.469718],\n",
      "       [-8.963547]], dtype=float32)]\n",
      "5100 0.3469591 [array([[ -3.873372,   8.464799],\n",
      "       [-10.794346, -12.795165]], dtype=float32), array([[ 9.533114],\n",
      "       [-9.020823]], dtype=float32)]\n",
      "5200 0.34693724 [array([[ -3.8890388,   8.480727 ],\n",
      "       [-10.866232 , -12.865772 ]], dtype=float32), array([[ 9.596027],\n",
      "       [-9.077658]], dtype=float32)]\n",
      "5300 0.34691632 [array([[ -3.904512,   8.496444],\n",
      "       [-10.937547, -12.935854]], dtype=float32), array([[ 9.658481],\n",
      "       [-9.134083]], dtype=float32)]\n",
      "5400 0.3468968 [array([[ -3.9197843,   8.511955 ],\n",
      "       [-11.008333 , -13.005436 ]], dtype=float32), array([[ 9.720499],\n",
      "       [-9.190108]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500 0.34687892 [array([[ -3.9348764,   8.527269 ],\n",
      "       [-11.078599 , -13.074549 ]], dtype=float32), array([[ 9.7821045],\n",
      "       [-9.245768 ]], dtype=float32)]\n",
      "5600 0.34686166 [array([[ -3.9497943,   8.542395 ],\n",
      "       [-11.148373 , -13.143216 ]], dtype=float32), array([[ 9.843322],\n",
      "       [-9.30108 ]], dtype=float32)]\n",
      "5700 0.34684575 [array([[ -3.9645407,   8.557341 ],\n",
      "       [-11.21769  , -13.211456 ]], dtype=float32), array([[ 9.904167],\n",
      "       [-9.356059]], dtype=float32)]\n",
      "5800 0.34683087 [array([[ -3.9791043,   8.572117 ],\n",
      "       [-11.286566 , -13.279292 ]], dtype=float32), array([[ 9.964662],\n",
      "       [-9.410726]], dtype=float32)]\n",
      "5900 0.34681663 [array([[ -3.9935272,   8.586733 ],\n",
      "       [-11.355023 , -13.3467455]], dtype=float32), array([[10.024824],\n",
      "       [-9.465097]], dtype=float32)]\n",
      "6000 0.34680316 [array([[ -4.00779 ,   8.601185],\n",
      "       [-11.423072, -13.413839]], dtype=float32), array([[10.08467 ],\n",
      "       [-9.519188]], dtype=float32)]\n",
      "6100 0.3467909 [array([[ -4.021907,   8.61549 ],\n",
      "       [-11.490736, -13.480579]], dtype=float32), array([[10.144216],\n",
      "       [-9.57301 ]], dtype=float32)]\n",
      "6200 0.34677914 [array([[ -4.0358787,   8.629649 ],\n",
      "       [-11.558049 , -13.546992 ]], dtype=float32), array([[10.203476],\n",
      "       [-9.626586]], dtype=float32)]\n",
      "6300 0.34676802 [array([[ -4.049691,   8.643667],\n",
      "       [-11.625021, -13.613096]], dtype=float32), array([[10.262458],\n",
      "       [-9.679916]], dtype=float32)]\n",
      "6400 0.34675753 [array([[ -4.063398,   8.657548],\n",
      "       [-11.691657, -13.678894]], dtype=float32), array([[10.321185],\n",
      "       [-9.73302 ]], dtype=float32)]\n",
      "6500 0.34674755 [array([[ -4.0769844,   8.671308 ],\n",
      "       [-11.757983 , -13.7444105]], dtype=float32), array([[10.379662],\n",
      "       [-9.785904]], dtype=float32)]\n",
      "6600 0.346738 [array([[ -4.0904284,   8.684931 ],\n",
      "       [-11.824001 , -13.8096485]], dtype=float32), array([[10.437906],\n",
      "       [-9.838588]], dtype=float32)]\n",
      "6700 0.3467294 [array([[ -4.1037364,   8.698436 ],\n",
      "       [-11.889711 , -13.87462  ]], dtype=float32), array([[10.495919],\n",
      "       [-9.891069]], dtype=float32)]\n",
      "6800 0.3467211 [array([[ -4.116968,   8.711828],\n",
      "       [-11.955175, -13.939351]], dtype=float32), array([[10.553728],\n",
      "       [-9.943372]], dtype=float32)]\n",
      "6900 0.3467135 [array([[ -4.129993,   8.725109],\n",
      "       [-12.020328, -14.003834]], dtype=float32), array([[10.611328],\n",
      "       [-9.995497]], dtype=float32)]\n",
      "7000 0.3467061 [array([[ -4.1430044,   8.738283 ],\n",
      "       [-12.085254 , -14.0681   ]], dtype=float32), array([[ 10.668731],\n",
      "       [-10.047457]], dtype=float32)]\n",
      "7100 0.34669918 [array([[ -4.155935,   8.75135 ],\n",
      "       [-12.149934, -14.132154]], dtype=float32), array([[ 10.725951 ],\n",
      "       [-10.0992565]], dtype=float32)]\n",
      "7200 0.3466926 [array([[ -4.1686993,   8.764311 ],\n",
      "       [-12.214333 , -14.195995 ]], dtype=float32), array([[ 10.783002],\n",
      "       [-10.15091 ]], dtype=float32)]\n",
      "7300 0.34668618 [array([[ -4.181334,   8.777175],\n",
      "       [-12.278505, -14.259638]], dtype=float32), array([[ 10.839877],\n",
      "       [-10.202425]], dtype=float32)]\n",
      "7400 0.34668043 [array([[ -4.1939793,   8.789944 ],\n",
      "       [-12.342548 , -14.323088 ]], dtype=float32), array([[ 10.896585],\n",
      "       [-10.253796]], dtype=float32)]\n",
      "7500 0.3466748 [array([[ -4.206496,   8.80262 ],\n",
      "       [-12.406356, -14.386355]], dtype=float32), array([[ 10.953146],\n",
      "       [-10.305041]], dtype=float32)]\n",
      "7600 0.34666952 [array([[ -4.2188625,   8.815206 ],\n",
      "       [-12.469915 , -14.449445 ]], dtype=float32), array([[ 11.009556],\n",
      "       [-10.356161]], dtype=float32)]\n",
      "7700 0.34666455 [array([[ -4.2310653,   8.827699 ],\n",
      "       [-12.533249 , -14.512379 ]], dtype=float32), array([[ 11.065831],\n",
      "       [-10.407167]], dtype=float32)]\n",
      "7800 0.34665993 [array([[ -4.2432485,   8.840104 ],\n",
      "       [-12.596458 , -14.575145 ]], dtype=float32), array([[ 11.121949],\n",
      "       [-10.458052]], dtype=float32)]\n",
      "7900 0.34665546 [array([[ -4.255473,   8.85243 ],\n",
      "       [-12.659565, -14.637749]], dtype=float32), array([[ 11.177941],\n",
      "       [-10.508829]], dtype=float32)]\n",
      "8000 0.3466511 [array([[ -4.267545,   8.864676],\n",
      "       [-12.722475, -14.700205]], dtype=float32), array([[ 11.23381 ],\n",
      "       [-10.559505]], dtype=float32)]\n",
      "8100 0.34664705 [array([[ -4.279505,   8.876845],\n",
      "       [-12.785184, -14.762523]], dtype=float32), array([[ 11.28957 ],\n",
      "       [-10.610091]], dtype=float32)]\n",
      "8200 0.34664342 [array([[ -4.291331,   8.888942],\n",
      "       [-12.847691, -14.824697]], dtype=float32), array([[ 11.345214],\n",
      "       [-10.660584]], dtype=float32)]\n",
      "8300 0.34663975 [array([[ -4.303025,   8.900958],\n",
      "       [-12.910002, -14.886737]], dtype=float32), array([[ 11.400753],\n",
      "       [-10.710993]], dtype=float32)]\n",
      "8400 0.3466364 [array([[ -4.314566,   8.912892],\n",
      "       [-12.972117, -14.948665]], dtype=float32), array([[ 11.456192],\n",
      "       [-10.761322]], dtype=float32)]\n",
      "8500 0.34663343 [array([[ -4.326084,   8.924763],\n",
      "       [-13.034112, -15.01047 ]], dtype=float32), array([[ 11.51151],\n",
      "       [-10.81157]], dtype=float32)]\n",
      "8600 0.34663045 [array([[ -4.337778,   8.936583],\n",
      "       [-13.096194, -15.072127]], dtype=float32), array([[ 11.566724],\n",
      "       [-10.86173 ]], dtype=float32)]\n",
      "8700 0.34662744 [array([[ -4.3494377,   8.948313 ],\n",
      "       [-13.15814  , -15.133685 ]], dtype=float32), array([[ 11.621843],\n",
      "       [-10.911815]], dtype=float32)]\n",
      "8800 0.34662464 [array([[ -4.360968,   8.959976],\n",
      "       [-13.219922, -15.19513 ]], dtype=float32), array([[ 11.676868],\n",
      "       [-10.961826]], dtype=float32)]\n",
      "8900 0.3466223 [array([[ -4.372369,   8.971586],\n",
      "       [-13.281578, -15.256454]], dtype=float32), array([[ 11.7318125],\n",
      "       [-11.011777 ]], dtype=float32)]\n",
      "9000 0.34661964 [array([[ -4.3836684,   8.983126 ],\n",
      "       [-13.343048 , -15.317695 ]], dtype=float32), array([[ 11.786675],\n",
      "       [-11.061668]], dtype=float32)]\n",
      "9100 0.34661716 [array([[ -4.3947935,   8.994597 ],\n",
      "       [-13.404393 , -15.378831 ]], dtype=float32), array([[ 11.84146 ],\n",
      "       [-11.111503]], dtype=float32)]\n",
      "9200 0.34661517 [array([[ -4.4059277,   9.00602  ],\n",
      "       [-13.465585 , -15.439862 ]], dtype=float32), array([[ 11.896175 ],\n",
      "       [-11.1612835]], dtype=float32)]\n",
      "9300 0.34661293 [array([[ -4.4169  ,   9.017368],\n",
      "       [-13.526609, -15.500801]], dtype=float32), array([[ 11.950817],\n",
      "       [-11.211015]], dtype=float32)]\n",
      "9400 0.34661075 [array([[ -4.4277325,   9.02867  ],\n",
      "       [-13.587514 , -15.561649 ]], dtype=float32), array([[ 12.005389],\n",
      "       [-11.260698]], dtype=float32)]\n",
      "9500 0.34660888 [array([[ -4.4385695,   9.039924 ],\n",
      "       [-13.64824  , -15.622413 ]], dtype=float32), array([[ 12.059899],\n",
      "       [-11.310335]], dtype=float32)]\n",
      "9600 0.34660697 [array([[ -4.449136,   9.051099],\n",
      "       [-13.708837, -15.683097]], dtype=float32), array([[ 12.114348],\n",
      "       [-11.359928]], dtype=float32)]\n",
      "9700 0.34660542 [array([[ -4.4596972,   9.062245 ],\n",
      "       [-13.7692995, -15.743709 ]], dtype=float32), array([[ 12.168747],\n",
      "       [-11.409494]], dtype=float32)]\n",
      "9800 0.34660363 [array([[ -4.470172,   9.07331 ],\n",
      "       [-13.829648, -15.804213]], dtype=float32), array([[ 12.223082],\n",
      "       [-11.459007]], dtype=float32)]\n",
      "9900 0.3466022 [array([[ -4.4804764,   9.08434  ],\n",
      "       [-13.889834 , -15.864656 ]], dtype=float32), array([[ 12.277366],\n",
      "       [-11.508498]], dtype=float32)]\n",
      "10000 0.346601 [array([[ -4.4909563,   9.095307 ],\n",
      "       [-13.949982 , -15.925024 ]], dtype=float32), array([[ 12.328274],\n",
      "       [-11.556336]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[5.0001043e-01]\n",
      " [9.9996495e-01]\n",
      " [4.9998534e-01]\n",
      " [2.4368701e-05]] \n",
      "Correct:  [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_log\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-3-8cc03c8d0094>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-8cc03c8d0094>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=\"./logs/xor_log\"\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "tensorboard --logdir='./logs/xor_log'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
