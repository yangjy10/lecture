{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import datas.mnist_data as mnist_local\n",
    "from data import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "# ignore future waring\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "#from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 트레이닝 파라메터\n",
    "learning_rate = 0.01\n",
    "num_steps = 30000\n",
    "batch_size = 256\n",
    "\n",
    "display_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 네트워크 파라메터\n",
    "num_hidden_1 = 256 # 1st layer num features\n",
    "num_hidden_2 = 10 # 2nd layer num features (the latent dim)\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 생성된 이미지들을 저장할 generated_outputs 폴더를 생성합니다.\n",
    "num_img = 0\n",
    "if not os.path.exists('generated_output/VariationalAutoencdoer/'):\n",
    "    os.makedirs('generated_output/VariationalAutoencdoer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 생성된 MNIST 이미지를 8x8 Grid로 보여주는 plot 함수를 정의합니다.\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(sample.reshape(28, 28))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 변수 초기화 (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X(이미지)의 입력값(No labels, only pictures)\n",
    "X = tf.placeholder(np.float32, [None, num_input]) # 무한대 x 784 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 모델의 wright와 bias의 배열값\n",
    "# Variables\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(glorot_init([num_input, num_hidden_1])),\n",
    "    'z_mean': tf.Variable(glorot_init([num_hidden_1, num_hidden_2])),\n",
    "    'z_std': tf.Variable(glorot_init([num_hidden_1, num_hidden_2])),\n",
    "    'decoder_h1': tf.Variable(glorot_init([num_hidden_2, num_hidden_1])),\n",
    "    'decoder_out': tf.Variable(glorot_init([num_hidden_1, num_input]))\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(glorot_init([num_hidden_1])),\n",
    "    'z_mean': tf.Variable(glorot_init([num_hidden_2])),\n",
    "    'z_std': tf.Variable(glorot_init([num_hidden_2])),\n",
    "    'decoder_b1': tf.Variable(glorot_init([num_hidden_1])),\n",
    "    'decoder_out': tf.Variable(glorot_init([num_input]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "#input_image = tf.placeholder(tf.float32, shape=[None, num_input])\n",
    "encoder = tf.matmul(X, weights['encoder_h1']) + biases['encoder_b1']\n",
    "encoder = tf.nn.tanh(encoder)\n",
    "z_mean = tf.matmul(encoder, weights['z_mean']) + biases['z_mean']\n",
    "z_std = tf.matmul(encoder, weights['z_std']) + biases['z_std']\n",
    "\n",
    "# Sampler: Normal (gaussian) random distribution\n",
    "eps = tf.random_normal(tf.shape(z_std), dtype=tf.float32, mean=0., stddev=1.0,\n",
    "                       name='epsilon')\n",
    "z = z_mean + tf.exp(z_std / 2) * eps\n",
    "\n",
    "# Building the decoder (with scope to re-use these layers later)\n",
    "decoder = tf.matmul(z, weights['decoder_h1']) + biases['decoder_b1']\n",
    "decoder = tf.nn.tanh(decoder)\n",
    "decoder = tf.matmul(decoder, weights['decoder_out']) + biases['decoder_out']\n",
    "decoder = tf.nn.sigmoid(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 인코더 설정\n",
    "def encode_func(x):\n",
    "    en1 = tf.matmul(X, weights['encoder_h1']) + biases['encoder_b1']\n",
    "    en2 = tf.nn.tanh(en1)\n",
    "    z_m = tf.matmul(en2, weights['z_mean']) + biases['z_mean']\n",
    "    z_s = tf.matmul(en2, weights['z_std']) + biases['z_std']\n",
    "    eps = tf.random_normal(tf.shape(z_s), dtype=tf.float32, mean=0., stddev=1.0,\n",
    "                       name='epsilon')\n",
    "    z = z_m\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 디코더 설정\n",
    "def decode_func(z) :\n",
    "    de1 = tf.matmul(z, weights['decoder_h1']) + biases['decoder_b1']\n",
    "    de1 = tf.nn.tanh(de1)\n",
    "    de2 = tf.matmul(de1, weights['decoder_out']) + biases['decoder_out']\n",
    "    recon = tf.nn.sigmoid(de2)\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VAE Loss function 정의\n",
    "def vae_loss(x_reconstructed, x_true):\n",
    "    # Reconstruction loss\n",
    "    encode_decode_loss = x_true * tf.log(1e-10 + x_reconstructed) \\\n",
    "                         + (1 - x_true) * tf.log(1e-10 + 1 - x_reconstructed)\n",
    "    encode_decode_loss = -tf.reduce_sum(encode_decode_loss, 1)\n",
    "    # KL Divergence loss\n",
    "    kl_div_loss = 1 + z_std - tf.square(z_mean) - tf.exp(z_std)\n",
    "    kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, 1)\n",
    "    return tf.reduce_mean(encode_decode_loss + kl_div_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "encode_op = encode_func(X)\n",
    "decode_op = decode_func(encode_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss Function 및 optimizer 설정\n",
    "loss_op = vae_loss(decode_op, X)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 전체 변수 초기화 선언\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TF session 시작\n",
    "sess = tf.Session()\n",
    "\n",
    "# initializer 실행\n",
    "sess.run(init)\n",
    "\n",
    "# 학습 시작\n",
    "# 학습횟수(epoch = num_steps = 30000)\n",
    "num_img = 0\n",
    "for epoch in range(1, num_steps+1):    \n",
    "    # batch_size 만큼 다음 mini batch를 가져옴\n",
    "    X_images, _ = mnist.train.next_batch(batch_size)\n",
    "    \n",
    "    # 500번 반복할때마다 생성된 이미지를 저장합니다.\n",
    "    if epoch % 500 == 0:\n",
    "        \n",
    "        samples = sess.run(decode_op, feed_dict={encode_op: np.random.uniform(-1., 1., [16, 10])})\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('generated_output/VariationalAutoencdoer/%s_iter%d.png' % (str(num_img).zfill(3), epoch), bbox_inches='tight')\n",
    "        num_img += 1\n",
    "        plt.close(fig)\n",
    "    \n",
    "    \n",
    "    # 로그\n",
    "    _, l = sess.run([train_op, loss_op], feed_dict={X: X_images})\n",
    "    \n",
    "    # Display logs per step\n",
    "    if epoch % display_step == 0 or epoch == 1:\n",
    "        print('epoch %i: Minibatch Loss: %f' % (epoch, l))\n",
    "\n",
    "print(\"학습완료! (loss : \" + str(l) + \")\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 테스트 시작\n",
    "\n",
    "# Generator takes noise as input\n",
    "noise_input = tf.placeholder(tf.float32, shape=[None, num_hidden_2])\n",
    "# Rebuild the decoder to create image from noise\n",
    "decoder = tf.matmul(noise_input, weights['decoder_h1']) + biases['decoder_b1']\n",
    "decoder = tf.nn.tanh(decoder)\n",
    "decoder = tf.matmul(decoder, weights['decoder_out']) + biases['decoder_out']\n",
    "decoder = tf.nn.sigmoid(decoder)\n",
    "\n",
    "n = 4\n",
    "canvas_orig = np.empty((28 * n, 28 * n))\n",
    "canvas_recon = np.empty((28 * n, 28 * n))\n",
    "\n",
    "for i in range(n):\n",
    "    # MNIST test set\n",
    "    test_X, _ = mnist.train.next_batch(batch_size)\n",
    "    \n",
    "    g = sess.run(decode_op, feed_dict={X: test_X})\n",
    "\n",
    "    # 원본 이미지를 가져와서 출력\n",
    "    for j in range(n):\n",
    "        canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = test_X[j].reshape([28, 28])\n",
    "    # 재생성된 이미지를 가져와서 출력\n",
    "    for j in range(n):\n",
    "        # Draw the generated digits\n",
    "        canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "# 테스트 결과 출력\n",
    "print(\"Original Images\")     \n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Reconstructed Images\")\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
